<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html lang="en"><head>

 <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-149603772-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-149603772-1');
</script>

  <meta name="viewport" content="width=500">
  <link href="stylesheet.css" rel="stylesheet" type="text/css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
  <title>Stephanie Milani</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>

<body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
      <td>
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="90%" valign="middle">
              <p align="center">
                <name>Stephanie Milani</name>
              </p>
              <p>I am a Ph.D. student in the <a href="https://www.ml.cmu.edu/">Machine Learning Department</a> at <a href="https://www.cmu.edu/">Carnegie Mellon University</a>, where I am advised by <a href="https://feifang.info/">Fei Fang</a>. 
                Currently, I am a summer research intern at <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-montreal/">MSR Montreal</a>, where I am advised by <a href="http://www.cs.cmu.edu/~ggordon/">Geoff Gordon</a>. 
                I aim to create intelligent agents that can learn quickly, explain their decisions, and work harmoniously with people and other artificially intelligent agents. 
                I am particularly interested in reinforcement learning.
              </p>
              <p>
                I graduated in 2019 with a B.S. in Computer Science and a B.A. in Psychology from the <a href="https://www.umbc.edu/">University of Maryland, Baltimore County</a>. There, I was advised by <a href="https://www.csee.umbc.edu/~mariedj/">Marie desJardins</a> and <a href="https://www.csee.umbc.edu/~cmat/">Cynthia Matuszek</a>. 
                I have also had the pleasure of working with <a href="https://www.medschool.umaryland.edu/profiles/Wenzel-Jennifer/">Jennifer Wenzel</a>, <a href="https://www.ri.cmu.edu/ri-people/christoph-mertz/">Christoph Mertz</a>, <a href="https://www.ri.cmu.edu/ri-faculty/katia-sycara/">Katia Sycara</a>, <a href="https://davheld.github.io/">David Held</a>, and <a href="https://www.microsoft.com/en-us/research/people/kahofman/">Katja Hofmann</a>.

              </p>
	            <p>
		            I am open to and excited about collaborating with others. Please email me if you have any questions about a machine learning (or psychology) project, or if you are interested in a research collaboration.
	            </p>
              <p align=center>
                <a href="mailto:smilani@andrew.cmu.edu">Email</a> &nbsp/&nbsp
                <a href="data/StephanieMilani_CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=vx68rkMAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="http://www.linkedin.com/in/stephanie-milani/"> LinkedIn </a> &nbsp/&nbsp
		<a href="https://twitter.com/steph_milani"> Twitter </a>
              </p>
            </td>
            <td width="10%">
              <img src="images/me_cropped.png">
            </td>
          </tr>

        <!--table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>News</heading>
              <br><br>
              
              2019
              <ul>
		            <<li>December: Attended NeurIPS.</li>>
                <li>August: Joined Carnegie Mellon's Machine Learning Department</a> as a Ph.D. student.</li>
                <li>July - August: Worked with Fei Fang at Carnegie Mellon University for the second half of the summer.</li> 
                <li>July: Presented some new work at RLDM 2019.</li>
                <<li>June: Attended ICML.</li>>
                <li>June - July: Worked with Dave Held at Carnegie Mellon University for the first half of the summer.</li>
                <li>May: Graduated from UMBC!</li>
              </ul>
            </td>
          </tr>
        </table-->
      
      <!--<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="100%" valign="middle">
            <heading>Research Interests</heading>
            <p>
              I aim to create intelligent, morally-competent agents that can learn quickly, explain their decisions, and work harmoniously with people and other artificially intelligent agents.
              I'm particularly interested in reinforcement learning.
            </p>
          </td>
        </tr>-->
      
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Preprints</heading>
              <br><br>

    <a href="https://arxiv.org/abs/2202.08434">
    <papertitle>A Survey of Explainable Reinforcement Learning</papertitle></a>
            </a>
            <br>
            <strong>Stephanie Milani*</strong>,
            Nicholay Topin*,
            <a href="http://www.cs.cmu.edu/~mmv/">Manuela Veloso</a>,
            <a href="https://feifang.info/">Fei Fang</a>
            <br>
            <em>arXiv preprint</em>, 2022
            <br><br>
                  </td>
                  </tr>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tr>
              <td width="100%" valign="middle">
                <heading>Refereed Publications</heading>
                <br><br>

                <a href='https://arxiv.org/abs/2205.12449'>
                  <papertitle>MAVIPER: Learning Decision Tree Policies for Interpretable Multi-Agent Reinforcement Learning</papertitle>
                </a>
                  <br>
                  <strong>Stephanie Milani*</strong>,
                  Zhicheng Zhang*,
                  Nicholay Topin,
                  <a href="https://ryanzshi.github.io/">Zheyuan Ryan Shi</a>,
                  Charles Kamhoua, 
                  <a href="https://www.cs.ucr.edu/~epapalex/">Evangelos E. Papalexakis</a>,
                  <a href="https://feifang.info/">Fei Fang</a>
                  <br>
                  <em>ECML-PKDD</em>, 2022 
                  <br>
                  Previous version at <a href="https://www.dropbox.com/s/s3e1yqsnlz31gwc/EAAI-AAAI22_workshop_proceedings.pdf">AAAI-22 Explainable Agency in AI Workshop</a>
                <br><br>

                <a href="https://optlearnmas22.github.io/files/paper10.pdf">
                <papertitle>Learning to Play Adaptive Cyber Deception Game</papertitle></a>
                <br>
                Yinuo Du,
                Zimeng Song,
                <strong>Stephanie Milani</strong>,
                Coty Gonzalez,
                <a href="https://feifang.info/">Fei Fang</a>
                <br>
                <em>AAMAS OptLearnMAS Workshop</em>
                <br><br>

                <papertitle>The MineRL BASALT Competition on Fine-tuning from Human Feedback</papertitle>
                <br>
                Anssi Kanervisto, 
                <strong>Stephanie Milani</strong>,
                Karolis Ramanauskas, 
                Byron V. Galbraith, 
                Steven H. Wang, 
                Brandon Houghton, 
                Sharada Mohanty, 
                Rohin Shah 
                <br>
                <em>NeurIPS Competition Track</em>, 2022
                <br><br>
                <a href="https://openreview.net/forum?id=rt-c0N6Vk-9&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2022%2FWorkshop%2FGPL%2FAuthors%23your-submissions)">
                  <papertitle>Towards Flexible Inference in Sequential Decision Problems via Bidirectional Transformers</papertitle>
                    </a>
                  <br> 
                 Micah Carroll, 
                 Jessy Lin, 
                 Orr Paradise, 
                 Raluca Georgescu, 
                 Mingfei Sun, 
                 David Bignell, 
                  <strong>Stephanie Milani</strong>,
                  Katja Hofmann, 
                  Matthew Hausknecht, 
                  Anca Dragan, 
                  Sam Devlin 
                  <br>
                  <em>ICLR Workshop on Generalizable Policy Learning in the Physical World</em>, 2022
                  <br><br>

                  <a href="https://arxiv.org/abs/2202.10583">
                    <papertitle>MineRL Diamond 2021 Competition: Overview, Results, and Lessons Learned</papertitle>
                      </a>
                    <br> 
                    Anssi Kanervisto*,
                    <strong>Stephanie Milani*</strong>,
                    Karolis Ramanauskas,
                    Nicholay Topin, 
                    Zichuan Lin,
                    Junyuo Li,
                    Deheng Ye,
                    Qiang Fu,
                    Wei Yang,
                    Weijun Hong,
                    Zhongyue Huang,
                    Haicheng Chen,
                    Guangjun Zeng,
                    Yue Lin,
                    Vincent Micheli,
                    Eloi Alonso,
                    Francois Fleuret,
                    Alexander Nikulin,
                    Yury Belousov,
                    Oleg Svidchenko, 
                    Aleksei Shpilman
                    <br>
                    <em>PMLR: NeurIPS 2021 Competition and Demonstration Track</em>, 2022
                    <br><br>
                  
                  <papertitle>Retrospective on the 2021 MineRL BASALT Competition on Learning from Human Feedback</papertitle>
                    <br> 
                    Rohin Shah,
                    Steven H. Wang,
                    Cody Wild,
                    <strong>Stephanie Milani</strong>,
                    Anssi Kanervisto, 
                    Vinicius G. Goecks, 
                    Nicholas Waytowich,
                    David Watkins-Valls,
                    Bharat Prakash,
                    Edmund Mills,
                    Divyansh Garg, 
                    Alexander Fries,
                    Alexandra Souly,
                    Chan Jun Shern,
                    Daniel del Castillo,
                    Tom Lieberum 
                    <br>
                    <em>PMLR: NeurIPS 2021 Competition and Demonstration Track</em>, 2022
                    <br><br>

  <papertitle>How Humans Perceive Human-like Behavior in Video Game Navigation</papertitle>
</a>
<br>
<a href="https://www.microsoft.com/en-us/research/people/t-ezuniga/">Evelyn Zuniga*</a>,
<strong>Stephanie Milani*</strong>,
Guy Leroy*,
Jaroslaw Rzepecki,
Raluca Georgescu, 
Ida Momennejad,
Dave Bignell, 
Mingfei Sun,
Alison Shaw,
Gavin Costello,
<a href="https://mikhailjacob.in/">Mikhail Jacob</a>,
Sam Devlin,
<a href="https://www.microsoft.com/en-us/research/people/kahofman/">Katja Hofmann</a>
<br>
<em>CHI Late Breaking Work</em>, 2022
<br><br>

  <papertitle>Understanding Human-like Behavior in Video Game Navigation</papertitle>
      </a>
      <br>
      <a href="https://www.microsoft.com/en-us/research/people/t-ezuniga/">Evelyn Zuniga*</a>,
      <strong>Stephanie Milani*</strong>,
      <a href="https://mikhailjacob.in/">Mikhail Jacob</a>,
      <a href="https://www.microsoft.com/en-us/research/people/kahofman/">Katja Hofmann</a>
      <br>
      <em>NeurIPS Workshop on Human-Centered AI</em>, 2021
      <br><br>

  <papertitle>The MineRL Diamond Competition on Sample Efficient Reinforcement Learning</papertitle>
    </a>
    <br>
    <a href="http://wguss.ml/">William H. Guss</a>, 
    Alara Dirik*, 
    Byron Galbraith*, 
    Brandon Houghton*, 
    Anssi Kanervisto*,
    <a href="https://www.microsoft.com/en-us/research/people/nkuno/">Noboru Sean Kuno</a>,
    <strong>Stephanie Milani*</strong>,
    <a href="https://spmohanty.com/">Sharada Mohanty*</a>,
    Karolis Ramanauskas*, 
    <a href="https://www.cs.cmu.edu/~rsalakhu/">Ruslan Salakhutdinov*</a>,
    <a href="https://rohinshah.com/">Rohin Shah*</a>,
    Nicholay Topin*,
    Steven H. Wang*, 
    Cody Wild*
    <br>
    <em>NeurIPS Competition Track</em>, 2021
    <br><br>

  <papertitle>The MineRL BASALT Competition on Learning from Human Feedback</papertitle>
  </a>
  <br>
  <a href="https://rohinshah.com/">Rohin Shah</a>,
  Cody Wild,
  Steven H. Wang, 
  Neel Alex,
  Brandon Houghton, 
  <a href="http://wguss.ml/">William H. Guss</a>, 
  <strong>Stephanie Milani</strong>,
  Nicholay Topin, 
  <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/abbeel.html">Pieter Abbeel</a>,
  <a href="http://people.eecs.berkeley.edu/~russell/">Stuart Russell</a>,
  <a href="http://people.eecs.berkeley.edu/~anca/">Anca Dragan</a>
  <br>
  <em>NeurIPS Competition Track</em>, 2021
  <br><br>

	<a href="https://arxiv.org/abs/2106.03748">
 	  <papertitle>Towards Robust and Domain Agnostic Reinforcement Learning Competitions</papertitle></a>
		      <br>
		      <a href="http://wguss.ml/">William H. Guss</a>, 
		      <strong>Stephanie Milani</strong>, 
		      Nicholay Topin, 
		      Brandon Houghton, 
		      Sharada Mohanty, 
		      Andrew Melnik, 
		      Augustin Harter, 
		      Benoit Buschmaas, 
		      Bjarne Jaster, 
		      Christoph Berganski, 
		      Dennis Heitkamp, 
		      Marko Henning, 
		      Helge Ritter, 
		      Chengjie Wu, 
		      Xiaotian Hao, 
		      Yiming Lu, 
		      Hangyu Mao, 
		      Yihuan Mao, 
		      Chao Wang, 
		      Michal Opanowicz,
		      Anssi Kanervisto, 
		      Yanick Schraner, 
		      Christian Scheller, 
		      Xiren Zhou, 
		      Lu Liu, 
		      Daichi Nishio, 
		      Toi Tsuneda, 
		      Karolis Ramanauskas, 
		      Gabija Juceviciute
		      <br>
		      <em>Proceedings of the NeurIPS 2020 Competition & Demonstration Track</em>, 2021
		      <br><br>
		      
	<a href="https://arxiv.org/abs/2102.13045">
	  <papertitle>Iterative Bounding MDPs: Learning Interpretable Policies via Non-Interpretable Methods</papertitle></a>
		      <br>
		      Nicholay Topin,
		      <strong>Stephanie Milani</strong>,
		      <a href="https://feifang.info/">Fei Fang</a>,
		      <a href="http://www.cs.cmu.edu/~mmv/">Manuela Veloso</a>
		      <br>
		      <em>AAAI</em>, 2021
		      <br>
		      <a href='data/2021Topin_AAAI.bib'>bibtex</a>
		      <br><br>
		      
   <a href="https://books.google.com/books?hl=en&lr=&id=WGYQEAAAQBAJ&oi=fnd&pg=PA147&ots=axJqQJSguh&sig=2QQcvCpOv-eZea95L67qVvDo0j8#v=onepage&q&f=false">
          <papertitle>Harnessing the Power of Deception in Attack Graph-Based Security Games</papertitle>
		      </a>
                <br>
                <strong>Stephanie Milani</strong>,
                <a href="https://www.weiran-shen.info/">Weiran Shen</a>,
                Kevin S. Chan, 
                <a href="https://mason.gmu.edu/~svenkate/">Sridhar Venkatesan</a>,
                <a href="https://www.csiac.org/person/nandi-o-leslie/">Nandi O. Leslie</a>,
                <a href="https://www.csiac.org/person/charles-a-kamhoua/">Charles Kamhoua</a>,
                <a href="https://feifang.info/">Fei Fang</a>
                <br>
                <em>GameSec</em>, 2020
                <br>
                <a href="data/2020Milani_GameSec.bib">bibtex</a>
                <br><br>

    <a href="https://arxiv.org/abs/2003.05012">
                <papertitle>A Retrospective Analysis of the 2019 MineRL Competition on Sample Efficient Reinforcement Learning Using Human Priors</papertitle>
                </a>
                <br>
                <strong>Stephanie Milani</strong>, 
                Nicholay Topin,
                Brandon Houghton,
                <a href="http://wguss.ml/">William H. Guss</a>,
                <a href="https://spmohanty.com/">Sharada Mohanty</a>,
                Keisuke Nakata, 
                <a href="https://research.google/people/OriolVinyals/">Oriol Vinyals</a>,
                <a href="https://www.microsoft.com/en-us/research/people/nkuno/">Noboru Sean Kuno</a>
                <br>
                <em>Proceedings of the NeurIPS 2019 Competition & Demonstration Track</em>, 2020
                <br>
                <a href="data/2020Milani_PMLR.bib">bibtex</a>
                <br><br>

                <papertitle>NeurIPS2020 Competition: The MineRL Competition on Sample Efficient Reinforcement Learning using Human Priors</papertitle>
                <br>
                <a href="http://wguss.ml/">William H. Guss</a>,
                Mario Ynocente Castro*,
                <a href="https://www.microsoft.com/en-us/research/people/sadevlin/">Sam Devlin*</a>,
                Brandon Houghton*,
                <a href="https://www.microsoft.com/en-us/research/people/nkuno/">Noboru Sean Kuno*</a>,
                Crissman Loomis*,
                <strong>Stephanie Milani*</strong>, 
                <a href="https://spmohanty.com/">Sharada Mohanty*</a>,
                Keisuke Nakata*,
                <a href="https://www.cs.cmu.edu/~rsalakhu/">Ruslan Salakhutdinov*</a>, 
                <a href="http://joschu.net/">John Schulman*</a>,
                Shinya Shiroshita*,
                Nicholay Topin*,
                <a href="https://ummavi.github.io/">Avinash Ummadisingu*</a>,
                <a href="https://research.google/people/OriolVinyals/">Oriol Vinyals*</a>
                <br>
                <em>NeurIPS Competition Track</em>, 2020
                <br>
                <a href="data/2020Guss_NeurIPS.bib">bibtex</a>
                <br><br>

		<a href="https://arxiv.org/abs/1912.07544">
                <papertitle>Planning with Abstract, Learned Models While Learning Transferable Subtasks</papertitle>
                </a>
                <br>
                <a href="https://jwinder1.github.io/">John Winder</a>,
                <strong>Stephanie Milani</strong>, 
                <a href="http://matthewlanden.me/">Matthew Landen</a>,
                Erebus Oh, 
                <a href="https://sparr.io/">Shane Parr</a>, 
                <a href="https://shawnsquire.me/">Shawn Squire</a>,
                <a href="https://www.csee.umbc.edu/~mariedj/">Marie desJardins</a>,
		            <a href="https://www.csee.umbc.edu/~cmat/">Cynthia Matuszek</a>
                <br>
                <em>AAAI</em>, 2020
                <br>
                Previous versions at <a href="https://pdfs.semanticscholar.org/1142/60e0755e487a883d03aa761579791a2bc0f3.pdf#page=54">ICAPS-17 IntEx Workshop</a>, RLDM-17, and Do Good Robotics Symposium 2019
                <br>
                <a href="data/2020Winder_AAAI.bib">bibtex</a>
                <br><br>
  
    <a href="http://www.cse.msu.edu/~wangzh65/AI4EDU/papers/14.pdf">
                <papertitle>Intelligent Tutoring Strategies for Students with Autism Spectrum Disorder: A Reinforcement Learning Approach.</papertitle>
                </a>
                <br>
                <strong>Stephanie Milani*</strong>, 
                <a href="https://zhoufan.me/">Zhou Fan*</a>, 
                <a href="https://www.linkedin.com/in/saurgul/">Saurabh Gulati</a>,
                <a href="https://ix.cs.uoregon.edu/~thanhhng/">Thanh Nguyen</a>,
                <a href="https://feifang.info/">Fei Fang</a>,
                <a href="http://amulyayadav.com/">Amulya Yadav</a>
                <br>
                <em>AAAI Workshop on AI for Education</em>, 2020
                <br>
                <a href="data/2020Milani_AAAI.bib">bibtex</a>
                <br><br>

    <a href="https://arxiv.org/pdf/1904.10079.pdf">
                <papertitle>The MineRL Competition on Sample Efficient Reinforcement Learning using Human Priors</papertitle>
                </a>
                <br>
                <a href="http://wguss.ml/">William H. Guss</a>,
                Cayden Codel*,
                <a href="https://www.microsoft.com/en-us/research/people/kahofman/">Katja Hofmann*</a>,
                Brandon Houghton*,
                <a href="https://www.microsoft.com/en-us/research/people/nkuno/">Noboru Sean Kuno*</a>,
                <strong>Stephanie Milani*</strong>, 
                <a href="https://spmohanty.com/">Sharada Mohanty*</a>,
                <a href="http://www.diego-perez.net/">Diego Perez-Liebana*</a>, 
                <a href="https://www.cs.cmu.edu/~rsalakhu/">Ruslan Salakhutdinov*</a>, 
                Nicholay Topin*,
                <a href="http://www.cs.cmu.edu/~mmv/">Manuela Veloso*</a>,
                Phillip Wang*
                <br>
                <em>NeurIPS Competition Track</em>, 2019
                <br>
                <a href="data/2019Guss_NeurIPS.bib">bibtex</a>
                <br><br>

    <a href="https://arxiv.org/abs/2005.06041">
                  <papertitle>Guaranteeing Reproducibility in Deep Learning Competitions</papertitle>
                </a>
                <br>
                Brandon Houghton,
                <strong>Stephanie Milani</strong>,
                Nicholay Topin,
                <a href="http://wguss.ml/">William H. Guss</a>,
                <a href="https://www.microsoft.com/en-us/research/people/kahofman/">Katja Hofmann</a>,
                <a href="http://www.diego-perez.net/">Diego Perez-Liebana</a>, 
                <a href="http://www.cs.cmu.edu/~mmv/">Manuela Veloso</a>,
                <a href="https://www.cs.cmu.edu/~rsalakhu/">Ruslan Salakhutdinov</a>
                <br>
                <em>NeurIPS CiML Workshop</em>, 2019
                <br>
                <a href="data/2019Houghton_NeurIPS.bib">bibtex</a>
                <br><br>
    
    <!--papertitle>Planning with Abstract, Learned Models</papertitle>
                <br>
                <a href="https://jwinder1.github.io/">John Winder</a>,
                <strong>Stephanie Milani</strong>,
                <a href="http://matthewlanden.me/">Matthew Landen</a>,
                Erebus Oh,
                <a href="https://shawnsquire.me/">Shawn Squire</a>,
                <a href="https://www.csee.umbc.edu/~mariedj/">Marie desJardins</a>,
                <a href="https://www.csee.umbc.edu/~cmat/">Cynthia Matuszek</a>
                <br>
                <em>Do Good Robotics Symposium</em>, 2019
                <br>
                <a href="data/2019Winder_DGRS.bib">bibtex</a>
                <br><br-->
    
    <a href="http://cs.brown.edu/~mlittman/ftp/extendedabstracts.pdf#page=317">
                  <papertitle>Penalty-Modified Markov Decision Processes: Efficient Incorporation of Norms into Sequential Decision Making Problems</papertitle>
                </a>
                <br>
                <strong>Stephanie Milani</strong>,
                Nicholay Topin,
                <a href="https://www.ri.cmu.edu/ri-faculty/katia-sycara/">Katia Sycara</a>
                <br> 
                <em>RLDM</em>, 2019
                <br>
                <a href="data/2019Milani_RLDM.bib">bibtex</a>
                <br><br>

    <a href="http://www.aies-conference.com/wp-content/papers/main/AIES-19_paper_232.pdf">
                  <papertitle>Perceptions of Domestic Robots' Normative Behavior Across Cultures</papertitle>
                </a>
                <br>
                Huao Li,
                <strong>Stephanie Milani</strong>,
                Vigneshram Krishnamoorthy,
                <a href="http://www.pitt.edu/~cmlewis/">Michael Lewis</a>,
                <a href="https://www.ri.cmu.edu/ri-faculty/katia-sycara/">Katia Sycara</a>
                <br>
                <em>AI, Ethics, and Society</em>, 2019 
                <br>
                <a href="data/2019Li_AIES.bib">bibtex</a>
                <br><br>

    <!--a href="https://pdfs.semanticscholar.org/1142/60e0755e487a883d03aa761579791a2bc0f3.pdf#page=54">
                  <papertitle>Towards Planning with Hierarchies of Learned Markov Decision Processes</papertitle>
                </a>
                <br>
                <a href="https://jwinder1.github.io/">John Winder</a>,
                <a href="https://shawnsquire.me/">Shawn Squire</a>,
                <a href="http://matthewlanden.me/">Matthew Landen</a>,
                <strong>Stephanie Milani</strong>,
                <a href="https://www.csee.umbc.edu/~mariedj/">Marie desJardins</a>
                <br>
                <em>ICAPS Workshop on Integrated Planning, Acting, and Execution</em>, 2017
                <br>
                <a href="data/2017Winder_ICAPSIntEx.bib">bibtex</a>
                <br><br>
  
    <papertitle>R-AMDP: Model-Based Learning for Abstract Markov Decision Process Hierarchies</papertitle>
                <br>
                <a href="https://shawnsquire.me/">Shawn Squire</a>,
                <a href="https://jwinder1.github.io/">John Winder</a>,
                <a href="http://matthewlanden.me/">Matthew Landen</a>,
                <strong>Stephanie Milani</strong>,
                <a href="https://www.csee.umbc.edu/~mariedj/">Marie desJardins</a>
                <br>
                <em>RLDM</em>, 2017
                <br>
                <a href="data/2017Squire_RLDM.bib">bibtex</a-->
              </td>
            </tr>
        </table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td>
              <br>
              <p align="right">
                <font size="2">
                  I got this great website <a href="https://jonbarron.info/">here</a>.
                </font>
              </p>
            </td>
          </tr>
        </table>
      </td>
    </tr>
  </table>
</body>

</html>
